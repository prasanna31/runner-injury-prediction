{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:03:18.694226Z",
     "iopub.status.busy": "2025-05-07T04:03:18.693919Z",
     "iopub.status.idle": "2025-05-07T04:03:18.707408Z",
     "shell.execute_reply": "2025-05-07T04:03:18.706531Z",
     "shell.execute_reply.started": "2025-05-07T04:03:18.694205Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 features based on importance:\n",
      "1. km Z5-T1-T2.6\n",
      "2. perceived trainingSuccess.6\n",
      "3. perceived recovery\n",
      "4. perceived exertion.4\n",
      "5. perceived exertion.3\n",
      "6. km sprinting.5\n",
      "7. nr. sessions.5\n",
      "8. km Z5-T1-T2.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the feature ranking CSV file\n",
    "df = pd.read_csv('/kaggle/working/day_2048/featureranking.csv', header=None)\n",
    "\n",
    "# Assuming the last row contains the aggregate feature importance scores\n",
    "feature_names = df.iloc[0].tolist()\n",
    "importance_scores = df.iloc[-1].astype(float).tolist()\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding importance scores\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance_scores\n",
    "})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "sorted_features = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Extract the top 8 features\n",
    "top_8_features = sorted_features['Feature'].head(8).tolist()\n",
    "\n",
    "print(\"Top 8 features based on importance:\")\n",
    "for i, feature in enumerate(top_4_features, start=1):\n",
    "    print(f\"{i}. {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:05:14.967193Z",
     "iopub.status.busy": "2025-05-07T04:05:14.966815Z",
     "iopub.status.idle": "2025-05-07T04:05:15.014065Z",
     "shell.execute_reply": "2025-05-07T04:05:15.013385Z",
     "shell.execute_reply.started": "2025-05-07T04:05:14.967163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Injury Risk Prediction: 0.69 → ⚠️ High\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessing and models\n",
    "means = joblib.load(\"/kaggle/working/stores/stats/input_train_means.pkl\")\n",
    "stds = joblib.load(\"/kaggle/working/stores/stats/input_train_std.pkl\")\n",
    "feature_order = joblib.load(\"/kaggle/working/stores/stats/feature_order.pkl\")  # List of 70 features\n",
    "model_filenames = [\n",
    "    \"xgb_model_8061.joblib\",\n",
    "]\n",
    "\n",
    "# Load the models\n",
    "models = [joblib.load(f\"/kaggle/working/stores/{filename}\") for filename in model_filenames]\n",
    "\n",
    "# Define preprocessing\n",
    "def preprocess_input_1(user_input_dict):\n",
    "    # Create a DataFrame with all required features\n",
    "    input_df = pd.DataFrame(columns=feature_order)\n",
    "    input_df.loc[0] = [user_input_dict.get(feat, means.get(feat, 0)) for feat in feature_order]\n",
    "    \n",
    "    # Standardize the input\n",
    "    standardized = (input_df - means[feature_order]) / stds[feature_order]\n",
    "    \n",
    "    # Convert to NumPy array\n",
    "    return standardized.to_numpy()\n",
    "\n",
    "# Define preprocessing\n",
    "def preprocess_input(user_input_dict):\n",
    "    # Create a DataFrame with all required features\n",
    "    input_data = {feat: [user_input_dict.get(feat, 0)] for feat in feature_order}\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    \n",
    "    # Standardize the input\n",
    "    standardized = (input_df - means[feature_order]) / stds[feature_order]\n",
    "    \n",
    "    # Convert to NumPy array\n",
    "    return standardized.to_numpy()\n",
    "# Predict injury risk\n",
    "def predict_injury_risk(input_vec):\n",
    "    preds = [model.predict_proba(input_vec)[0][1] for model in models]\n",
    "    return np.mean(preds)\n",
    "\n",
    "# --- Example usage ---\n",
    "# Provide values for the top 4 features; others will be filled with mean values\n",
    "user_input_dict = {\n",
    "    \"km Z5-T1-T2.6\": 20.7,\n",
    "    \"perceived trainingSuccess.6\": 32.8,\n",
    "    \"perceived recovery\": 0.83,\n",
    "    \"perceived exertion.4\": 12.9,\n",
    "    \"perceived exertion.3\": 1.6,\n",
    "    \"km sprinting.5\": 9.0,\n",
    "    \"nr. sessions.5\": 9.8,\n",
    "    \"km Z5-T1-T2.4\": 9.6\n",
    "}\n",
    "\n",
    "# Run prediction\n",
    "x_input = preprocess_input(user_input_dict)\n",
    "injury_risk = predict_injury_risk(x_input)\n",
    "print(f\"🔍 Injury Risk Prediction: {injury_risk:.2f} → {'⚠️ High' if injury_risk > 0.5 else '✅ Low'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7326978,
     "sourceId": 11674503,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
